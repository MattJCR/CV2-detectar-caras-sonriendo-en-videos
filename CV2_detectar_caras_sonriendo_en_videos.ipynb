{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMW24WLy4fyAign0tcvV7vT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MattJCR/CV2-detectar-caras-sonriendo-en-videos/blob/master/CV2_detectar_caras_sonriendo_en_videos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pytube \n",
        "# Importamos las bibliotecas necesarias\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from pytube import YouTube\n",
        "from IPython.display import Video\n",
        "from base64 import b64encode\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOi0tcQ1Q0H-",
        "outputId": "82df7d94-d3a8-46c3-e22c-f65761f443f4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.8/dist-packages (12.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicio de la medición de tiempo\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "9CUF5RRXSsuK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL del video\n",
        "video_url = \"https://www.youtube.com/watch?v=RENDRigVHWU\"\n",
        "# download the video using pytube\n",
        "yt = YouTube(video_url)\n",
        "# Obtener la duración del video en segundos\n",
        "yt_duration = yt.length\n",
        "video = yt.streams.get_highest_resolution()\n",
        "\n",
        "# Descarga el video a un archivo en el directorio actual\n",
        "url = video.download()\n",
        "print('Ruta del video:',url)\n",
        "\n",
        "# Abrimos el video con cv2\n",
        "video = cv2.VideoCapture(url)\n",
        "\n",
        "# Abrir el video con una tasa de fps de 24 (Reduce el tiempo de tratamiento al tener menos FPS)\n",
        "FPS = 24\n",
        "video.set(cv2.CAP_PROP_FPS, FPS)\n",
        "\n",
        "# Comprueba si se ha podido abrir el video\n",
        "if not video.isOpened():\n",
        "    print(\"Error al abrir el video\")\n",
        "    exit()\n",
        "\n",
        "# Creamos una instancia del detector de caras de cv2\n",
        "#face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") \n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt.xml\") # Da buenos resultados\n",
        "#face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt2.xml\")\n",
        "#face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_alt_tree.xml\")\n",
        "#face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_upperbody.xml\") # No da muy buenos resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4BCfroiQrtA",
        "outputId": "44b8b37d-384f-41fc-dc8a-229b24427ea7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ruta del video: /content/Anuncio McDonald´s - Estoy probando cosas nuevas - Publicidad Comercial Spot 2017.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ancho y alto del video\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Crea un objeto VideoWriter para guardar el video editado\n",
        "video_writer = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*\"MP4V\"), FPS, (width, height))"
      ],
      "metadata": {
        "id": "fatf_Ry8V8PW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_smiling(face_region):\n",
        "    '''\n",
        "    DOC: https://dontrepeatyourself.org/post/smile-detection-with-python-opencv-and-haar-cascade/\n",
        "    '''\n",
        "    # Cargar el clasificador de sonrisas\n",
        "    smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')\n",
        "\n",
        "    # Detectar sonrisas en la región de la cara\n",
        "    #smiles = smile_cascade.detectMultiScale(face_region, 1.3, 8)\n",
        "\n",
        "    # Aplica el detector de sonrisa a la face_region\n",
        "    smile_rects, rejectLevels, levelWeights = smile_cascade.detectMultiScale3(face_region, 1.0355, 25, outputRejectLevels=True)\n",
        "    smiles = False\n",
        "    # Si no se detectó nada, consideramos esto como una detección de \"Not Smiling\"\n",
        "    if len(levelWeights) == 0:\n",
        "        smiles = False\n",
        "    else:\n",
        "        # Si 'levelWeights' es inferior a 2, clasificamos esto como \"Not Smiling\"\n",
        "        if max(levelWeights) < 2:\n",
        "            csmiles = False\n",
        "        # De lo contrario, hay una sonrisa en la face_region\n",
        "        else:\n",
        "            smiles = True\n",
        "    # Retornar verdadero si se detecta al menos una sonrisa, falso en caso contrario\n",
        "    return smiles\n"
      ],
      "metadata": {
        "id": "2lHMMiS726QE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a calcular el procentaje de \"smiling\" que tenemos en el video\n",
        "total_video = 0\n",
        "total_smile = 0"
      ],
      "metadata": {
        "id": "EitmN5m1B_IL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iteramos sobre cada frame del video\n",
        "while True:\n",
        "    total_video += 1\n",
        "    # Leemos el frame actual del video\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Si es el último frame, salimos del bucle\n",
        "    if not ret:\n",
        "      print('Video end')\n",
        "      break\n",
        "\n",
        "    # Convertimos el frame a una imagen de PIL\n",
        "    frame_pil = Image.fromarray(frame)\n",
        "    frame_pil = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_BGR2GRAY)\n",
        "    # Detectamos las caras en la imagen usando el detector\n",
        "    faces = face_cascade.detectMultiScale(\n",
        "          frame_pil,\n",
        "          scaleFactor = 1.0625,\n",
        "          minNeighbors = 8\n",
        "    )\n",
        "    # print(frame_pil.shape)\n",
        "    # Dibujamos un rectángulo en cada cara detectada\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Determinar si la cara está sonriendo\n",
        "        smile = is_smiling(frame_pil[y:y+h, x:x+w])\n",
        "        color = (0,255,0) if smile else (0,0,255)\n",
        "        if smile: total_smile += 1\n",
        "        # Dibujar un rectángulo alrededor de la cara y escribir si está sonriendo\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
        "        cv2.putText(frame, \"Smiling\" if smile else \"Not smiling\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "    # Escribe el frame editado en el archivo de salida\n",
        "    video_writer.write(frame)\n",
        "\n",
        "# Cerramos el video original\n",
        "video.release()\n",
        "# Cierra el archivo de salida\n",
        "video_writer.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDFqe0PlOl1w",
        "outputId": "3aca5f61-91b4-4edb-cf6a-16c669ea5b2b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducir el video\n",
        "from IPython.display import Video\n",
        "video_file = './output.mp4'\n",
        "Video(video_file, width=640, height=480)\n",
        " "
      ],
      "metadata": {
        "id": "mNZpc397Xr_J",
        "colab": {
          "resources": {
            "http://localhost:8080/output.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "739c55d9-dd14-4bd7-e470-0238548a2fe1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"./output.mp4\" controls  width=\"640\"  height=\"480\">\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final de la medición de tiempo\n",
        "end_time = time.time()\n",
        "\n",
        "# Cálculo del tiempo de ejecución en minutos\n",
        "elapsed_time_minutes = (end_time - start_time) / 60\n",
        "\n",
        "# Mostrar el tiempo de ejecución en minutos\n",
        "print(\"Tiempo de ejecución:\", elapsed_time_minutes, \"minutos\")\n",
        "\n",
        "# Mostrar la duración del video\n",
        "print(\"Duración del video:\", yt_duration / 60, \"minutos\")\n",
        "\n",
        "print('Smiling:',str(total_smile/total_video) + '%')"
      ],
      "metadata": {
        "id": "tUniZb5GSz1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca3bcdd-4a67-4372-f802-3b253c4565cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución: 11.641462389628092 minutos\n",
            "Duración del video: 0.5166666666666667 minutos\n",
            "Smiling: 0.14790575916230367%\n"
          ]
        }
      ]
    }
  ]
}